[{"categories":null,"content":"Ambilight is a technology of Bias lighting used in Phillips TVs which illumitates the back of your tv with colors related to the image displayed. Their solution is expensive, but you can create your own solution using an ESP 8266 controller and some cheap led strips. In order to adapt the lights to the image, the ambilight system needs to capture the images displayed on your tv. There are 2 main ways to do that: you can use a physical box to capture the video using an HDMI splitter and an acquisition card between your devices (Mi Box, Nvidia Shield, Xbox …) and your TV or you can use a software solution to directly stream the video from a device (PC, Android TV …). ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:0:0","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"First Method My first attempt was with the fist method (which was at that time the most used). The advantages are that you don’t need to install a third-party software in order to connect a device to your ambilight. You only need to plug the HDMI output in the splitter and it should work. You can even connect an HDMI switch before the splitter to connect multiple devices to your amblight system. However a stream may be protected with HDCP: a DRM protection which prevents it from being recorded, but there are many flaws in this technology and you can find some cheap HDMI splitters or HDMI-to-RCA converters from China that are able to strip the HDCP to obtain a readable stream. You then need to capture and process the video signal, for this task I used an RCA-to-USB key (the image quality isn’t important as the image is only used to detect the colors on the borders of the image). I used a Raspberry PI B+ to process the image and an arduino to control the led strips. The schema looked like this: Schema of the first version\" Schema of the first version I then sticked some WS2812B led strips behind the TV and renovated an old metal box to fit all the components for the ambilight system. This box already had an integrated power supply that I used to power the raspberry pi and the leds in 5V. The box that I recovered Filling the box with all the components The finished result On the software side, I used Hyperion (the first version) and the Hypercon.jar program to create the configuration file. The Raspberry PI would then send the orders to the connected arduino card that controlled the leds. the final result on the tv\" the final result on the tv This method worked pretty well but the box was pretty big and when I moved in, I didn’t have it on hand (nor did I have the necessary components to build a new one). So I decided to try another method. ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:1:0","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Second Method ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:0","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Presentation With this second solution, the splitter, converter and grabber are no longer needed: I just connect the HDMI devices directly to my tv and these devices will stream their video to an external server with Hyperion-ng (a new version of hyperion) which will send led control commands to an ESP 8266 over wifi (using E 1.31). Note that with this version, it will be impossible to capture DRM protected content. Schema of the second version\" Schema of the second version ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:1","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Configuration of the Hyperion Clients To stream the video feed from my android tv box, I used the hyperion-android-grabber app and for my PC I used the HyperionScreenCap software. To install a third-party apk on android tv, you need to enable ADB in the developer settings and connect to your box from your PC with adb connect 192.168.1.X You can then type adb install ./tv-release.apk to install the apk on your box. The app sould appear in your applications menu, if this is not the case, you can launch it manually with adb shell am start -n com.abrenoch.hyperiongrabber/.tv.activities.MainActivity. You can then go in the app’s settings and configure the IP of your server and the protobuf port (that will be used to receive the video from the box). You also need to set the priority between 100 and 199. For android tv, you may need to disable some hadware acceleration features that prevents the image from being captured, for Kodi, you need to disable the MediaCodec (Surface) feature in the settings. Note that any service serving drm protected content will not work (like Netflix, Amazon Prime, Twitch …). For youtube, you can bypass this protection by using the excellent SmartTube app. Android Grabber Settings Kodi Settings ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:2","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Configuration of the Hyperion Server Once the clients are configured, you need to setup the hyperion-ng server that will receive the video streams from the clients, process it and send the commands to you leds. You can use the following dockerfile and docker-compose to run it. FROMdebian:11-slimRUN apt-get update \u0026\u0026 apt-get install -y \\ wget jq \\ qtbase5-dev \\ libqt5serialport5-dev \\ libqt5sql5-sqlite \\ libqt5svg5-dev \\ libqt5x11extras5-dev \\ build-essential \\ libusb-1.0-0-dev \\ libcec-dev \\ libavahi-core-dev \\ libavahi-compat-libdnssd-dev \\ libxcb-util0-dev \\ libxcb-randr0-dev \\ libxcb-shm0-dev \\ libxcb-render0-dev \\ libxcb-image0-dev \\ libxrandr-dev \\ libxrender-dev \\ libturbojpeg0-dev \\ libssl-devRUN wget \"https://api.github.com/repos/hyperion-project/hyperion.ng/releases\" -O - | jq -r '.[0].assets[] | select(.name | contains(\"x86_64.deb\")).browser_download_url' | wget -i - -O hyperion.deb \u0026\u0026 dpkg -i hyperion.debCMD \"/usr/share/hyperion/bin/hyperiond\" version:\"3\"services:hyperion:build:.volumes:- /app/docker/data/Hyperion:/root/.hyperionlabels:- traefik.http.routers.hyperion.rule=Host(`hyperion.domain.tld`)- traefik.http.routers.hyperion.tls=true- traefik.http.routers.hyperion.entrypoints=https_lan- traefik.http.services.hyperion.loadbalancer.server.port=8090- traefik.enable=truerestart:unless-stoppedports:- 19400:19400- 19444:19444- 19445:19445- 19333:19333 ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:3","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Configuration of the ESP8266 The last thing to configure is the ESP 8266, that will receive the commands from the Hyperion server (with the E1.31 protocol) and control the leds. To do this easily, we can use ESP Home (see my previous post here). With the basic config, you just need to add a neopixelbus component with the type, command pin and amount of leds, and add the E1.31 effect to allow hyperion to control the leds. While writing the configuration file, I also decided to add an infrared led to control my TV from Home Assistant. For this you can either attach an IR receiver to capture the IR codes from your remote or try to find the codes online. Fom my TV brand (LG) I have found the following gist with all the codes. esphome:name:ambilightplatform:ESP32board:esp32doit-devkit-v1# Enable logginglogger:# Enable Home Assistant APIapi:ota:password:\"\"wifi:ssid:!secret \"wifi_ssid\"password:!secret \"wifi_password\"manual_ip:static_ip:10.20.8.2gateway:10.20.1.1subnet:255.255.0.0# Enable fallback hotspot (captive portal) in case wifi connection failsap:ssid:\"Ambilight Fallback Hotspot\"password:\"\"captive_portal:status_led:pin:GPIO4############################ IR TV ON/OFF #############remote_transmitter:pin:GPIO5carrier_duty_percent:10%switch:- platform:templatename:\"LG Power\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF10EFnbits:32- platform:templatename:\"LG Input\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFD02Fnbits:32- platform:templatename:\"LG Input\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFD02Fnbits:32- platform:templatename:\"LG Up\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF02FDnbits:32- platform:templatename:\"LG Down\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF827Dnbits:32- platform:templatename:\"LG Right\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF609Fnbits:32- platform:templatename:\"LG Left\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFE01Fnbits:32- platform:templatename:\"LG OK\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF22DDnbits:32- platform:templatename:\"LG Exit\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFDA25nbits:32- platform:templatename:\"LG HDMI1\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF738Cnbits:32- platform:templatename:\"LG HDMI2\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF33CCnbits:32- platform:templatename:\"LG HDMI3\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF9768nbits:32- platform:templatename:\"LG Settings\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFC23Dnbits:32- platform:templatename:\"LG Vol+\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF40BFnbits:32- platform:templatename:\"LG Vol-\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DFC03Fnbits:32- platform:templatename:\"LG Mute\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF906Fnbits:32- platform:templatename:\"LG 3D\"turn_on_action:remote_transmitter.transmit_lg:data:0x20DF3BC4nbits:32########################## LEDs #####################e131:method: multicast # default:register E1.31 to Multicast groupwled:light:- platform:neopixelbustype:GRBpin:GPIO18num_leds:146name:\"TV LEDs\"variant:WS2812effects:- e131:universe:1channels:RGB- wled:port:21324 Wiring of the second version\" Wiring of the second version ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:4","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Configuration of Home Assistant (Optional) You should now be able to add all the esp home devices in Home Assistant. You can see below that I also configured the Hyperion integration. We now have a complete remote to control our tv thanks to the IR led and a light entity representing our led strip that we can use to either use like a normal color bulb, set it in E1.31 mode to allow hyperion to control it, or set it in WLED mode to allow it to sync with other wled devices (using the Effect menu). The devices in Home Assistant\" The devices in Home Assistant You can also see a TV switch in Home Assistant. I created this device to be able to switch the tv on and off using the IR code corrsponding to the “power” button on the remote and based on the TV’s status on the network (as you can see in the tv’s picture above this TV has an ethernet port, so if the TV is on, then we can ping its IP address). Here is the configuration used to create this device: switch:- platform:templateswitches:tv:value_template:\"{{ is_state('binary_sensor.tv_status', 'on') }}\"turn_on:service:switch.turn_ondata_template:entity_id:\u003e{% if is_state('binary_sensor.tv_status', 'off') %} switch.lg_power {% else %} null {% endif %}turn_off:service:switch.turn_ondata_template:entity_id:\u003e{% if is_state('binary_sensor.tv_status', 'on') %} switch.lg_power {% else %} null {% endif %}binary_sensor:- platform:pinghost:10.20.4.2name:tv_statuscount:2scan_interval:10 ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:2:5","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Bonus ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:3:0","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Fixing the audio bar My Phillips audio bar also stopped working after some time, so I decided to fix it. As I don’t have a lot of knowledge about electronics I wasen’t able to identify the faulty component on the board, so I simply ordered a cheap 2.1 amplifier. As this ampifier wouldn’t fit into the bar, I rewired the bar’s speakers to RCA plugs on the bar and then used these plugs to connect the bar to the amplifier. But there was no remote with this amplifier, it’s not much of a problem for the volume (as we can still adjust it from the tv) but it isn’t practical to power it on and off. So I created a simple plug with a 230v relay powered by a usb port. The usb plug is connected to the TV, so when the TV is powered on, the usb ports will also be powered, which will then power the relay and let the current pass to power the amplifier. Fixing the audio bar The usb relay plug ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:3:1","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"Conclusion We have seen 2 different methods to create an amibilght system and especially to capture video, both of them having their advantages and drawbacks. The second one requires less hardware and space but you need to install a client software on each device that you want to use (and some devices will just not work like the PS4 where you can’t install anything), moreover you can only use this method to capture unprotected content. In contrast to this, the first method, while requiring significantly more hardware, will likely allow you to capture pretty much anything and once the first setup is done, it should be only a matter of plugging the device on the HDMI switch to add a new device. So, in the next version (an hopefully the last one), I think that I will use a bit of both methods with a standalone capture device like in the first method based on a raspberry pi and either an RCA grabber or directly with a CSI-to-HDMI adapter, and a command part kept as is, with the ESP8266 that allows to control the tv and the leds from Hyperion or directly from Home Assistant. ","date":"2022-05-30","objectID":"/2022/05/30/create-you-own-ambilight-solution/:4:0","tags":["docker","home assistant","iot","arduino","esp8266"],"title":"Create your own ambilight solution","uri":"/2022/05/30/create-you-own-ambilight-solution/"},{"categories":null,"content":"A few months ago, I started to search for some upscaling software to integrate into Zogwine, my media center with the goal of upscaling some of my old animes either on the fly or via some kind of preprocessing. I found quite a lot of projects on github, and especially the Video2X project which gathered many different projects and versions. So I decided to do a quick benchmark to decide which one to use. I would also recommend you to read this excellent arcticle from crunchyroll’s tech blog where they did their own tests for upscaling. ","date":"2022-01-14","objectID":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/:0:0","tags":["docker","python"],"title":"A comparison of upscaling software in 2021","uri":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/"},{"categories":null,"content":"Presentation of the benchmarked solutions I used the version 4.6.0 of Video2X and the version 3.3.1 of dandere2X. dandere2x is a faster version of Waifu2X, an upscaling software targeted to anime-style images and using a CNN approach. Video2X allows to use different upscaling software from the same interface. I have decided to test the following: Anime4KCPP an algorithmic approach to upscale anime-style images, based on the Anime4K algorithm Anime4KCPP_GPU Anime4KCPP in GPU mode Anime4KCPP_GPU_CNN Anime4KCPP with a CNN based algorithm and running on the GPU REALSR_NCNN_VULKAN an implementation of RealSR using the NCNN project and the Vulkan API SRMD_NCNN_VULKAN an implementation of SRMD using the NCNN project and the Vulkan API Waifu2X_NCNN_VULKAN an implementation of Waifu2X using NCNN and the Vulkan API Waifu2X_CAFFE_CUNET a Waifu2X implementation using Caffe and the CUDA API Waifu2X_CAFFE_UPRESNET10 the upresnet10 model for Waifu2X-Caffe running on the GPU Waifu2X_CAFFE_ANIME_STYLE_ART_RGB the anime_style_art_rgb model for Waifu2X-Caffe running on the GPU Waifu2X_CPP_CONVERTER Waifu2X C++ implementation running on the GPU You can find additional information on the different Waifu2X-Caffe models here. All the tests were ran using an X3 upscale ratio, to go from a 480p video to a 1440p video on a configuration with a Ryzen 7 5800X, 16GB RAM and an RTX 2070. Each upscale was run with this configuration without any other significant software running in the meantime. The input video was a 480p version of the 4th opening of Naruto Shippuden. The images shown here are only for educational purposes and belongs to their respective copyright owners. ","date":"2022-01-14","objectID":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/:1:0","tags":["docker","python"],"title":"A comparison of upscaling software in 2021","uri":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/"},{"categories":null,"content":"Gathering Results To process the results and compare the different solutions, I created a python script to extract a few frames (158, 500, 835, 1090, 1200 and 2200) for each video using ffmpeg. import os FRAMES = [158, 500, 835, 1090, 1200, 2200] def extractFrames(path, f, offset=0): print(\"extracting frames for: \"+f) for i in FRAMES: os.system('ffmpeg -i \"'+f+'\" -vf \"select=gte(n\\,'+str(i+offset)+')\" -vframes 1 '+path+'/frame_'+str(i+offset)+'.png ') base = os.getcwd() for dir in os.listdir(base): path = os.path.join(base, dir) if os.path.isdir(path): for file in os.listdir(path): if file.endswith(\".mkv\") or file.endswith(\".mp4\"): extractFrames(path, os.path.join(path, file)) break elif path.endswith(\".mkv\") or path.endswith(\".mp4\"): extractFrames(base, path, -1) In addition to this, I also executed the VMAF tool from Netflix to get some quality indicator for each video (compared to the original) using the easy-vmaf docker image like this: docker run –rm -v /srv/Documents/test_upscaling:/vid gfdavila/easyvmaf -r /vid/nt_op_480.mkv -d /vid/upscale_video2x_waifu2x_ncnn_vulkan/n_op_1440.mp4. I then graphed the results of pooled_metrics \u003e vmaf \u003e harmonic_mean for each method compared to their execution time. Here is the result: VMAF score and processing time for each upscaling solution\" VMAF score and processing time for each upscaling solution DOWNLOAD xls file ","date":"2022-01-14","objectID":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/:2:0","tags":["docker","python"],"title":"A comparison of upscaling software in 2021","uri":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/"},{"categories":null,"content":"Conclusions The input video has a length of 90 seconds, so for a real time upscaling system, only anime4KCPP qualifies. We can also note that a GLSL implementation of Anime4K exists which opens the door to client-side upscaling. We can exclude the implementations with a time greater than 4000s as more than 1 hour to process a 1min30 video is wayy too long. For real time upscaling the most efficient version seems to be video2x_anime4KCPP_cnn_gpu while dandere2x_waifu2x_caffe seems to bring the best quality for the lowest execution time among the potential pre-processing upscaling. Original vs Anime4KCPP_gpu vs Anime4KCPP_cnn_gpu\" Original vs Anime4KCPP_gpu vs Anime4KCPP_cnn_gpu We can see here that the cnn version of anime4KCPP brings quite interesting improvements with smoother curves while anime4KCPP_gpu ends up outputting a more blurry image than the original. Original vs Anime4KCPP_cnn_gpu\" Original vs Anime4KCPP_cnn_gpu We can note that while the image improvements are minor with Anime4KCPP_cnn_gpu, the this is not the case for the text, which is way more readable in the upscaled version. Original vs RealSR vs SRMD | Waifu2x_cunet vs Waifu2x_anime_style_art_rgb vs dandere2x\" Original vs RealSR vs SRMD | Waifu2x_cunet vs Waifu2x_anime_style_art_rgb vs dandere2x Original vs dandere2x\" Original vs dandere2x In opposition to the anime4K performance for the image, we can see some really impressive improvements with an image without any major pixelation for each Waifu2X methods. With the lowsest execution time among the non-realtime candidates, dandere2x is the clear winner of this benchmark. ","date":"2022-01-14","objectID":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/:3:0","tags":["docker","python"],"title":"A comparison of upscaling software in 2021","uri":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/"},{"categories":null,"content":"General Conclusion With this benchmark, I was able to determine the best upscaling software to use for my mediacenter. Anime4KCPP with the CNN version seems to be the best possible result for a realtime upscaling. While this remains an option, I don’t think that this feature would be implemented in the near future, as the benefits are quite thin. However, I discovered a very interesting option for a pre-processing feature (the file would be upscaled in background and not in realtime), dandere2x which proved to bring really impressive results. But while this solution is the fastest for non-realtime upscaling, this would still take more than 5 hours to upscale a single episode. This could be implemented as a feature that allows to upscale only a few selected files, a distributed system may also be a good lead if you have multiple powerful computers at home. ","date":"2022-01-14","objectID":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/:4:0","tags":["docker","python"],"title":"A comparison of upscaling software in 2021","uri":"/2022/01/14/a-comparison-of-upscaling-software-in-2021/"},{"categories":null,"content":"When I started to tinker with home automation and electronics a few years ago, it was common to use arduino cards to create DIY connected devices. You would then communicate with a central server to send and receive information. The communications were usually done using usb, ethernet (using an ethernet shield) or radio (2.4Ghz or 433Mhz) with projects like MySensors. Most of the time these cards were programmed using the “Arduino language” which is quite close to C++. I kept this habit when I switched to use the esp8266/esp32 cards but in the meantime, awesome projects were developped to facilitate the development of this kind of devices, especially dedicated ecosystems like ESP-Easy, Tasmota and ESP Home, which is the project that I decided to use. ","date":"2022-01-14","objectID":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/:0:0","tags":["docker","arduino","iot","home assistant","hardware"],"title":"Easily create you DIY IoT devices with ESP Home and Home Assistant","uri":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/"},{"categories":null,"content":"Why ESP Home ? While Tasmota and ESP-Easy are “battery-included” firmwares that you flash on the esp board and then configure with a web ui, ESP Home compiles a firmware specially for your device based on a yaml configuration file that tells it which kind of technology (SPI, I2C, UART) and sensor (dht22, HC-SR04 …) you are using and on which pins they are accessible. It even allows you to manally add C++ code through “lambdas”. Another great point of ESP Home is the native integration to Home Assistant (a very powerful home automation system) so we can focus on actually creating our IoT device instead of bothering about communication with the server. So let’s get started ! ","date":"2022-01-14","objectID":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/:1:0","tags":["docker","arduino","iot","home assistant","hardware"],"title":"Easily create you DIY IoT devices with ESP Home and Home Assistant","uri":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/"},{"categories":null,"content":"Getting started with ESP Home While this is not mandatory, I would recommend to install the ESP Home server using the docker image, which will facilitate the development of our devices with a user friendly web interface. (You can also skip this step and use directly ESP Home in CLI). So, I created the following docker-compose file to start the esphome dashboard and access it using traefik. I also decided to use ping instead of mdns to check for device status. version:\"3\"services:esphome:image:esphome/esphomeenvironment:- TZ=Europe/Paris- ESPHOME_DASHBOARD_USE_PING=truevolumes:- /app/docker/data/EspHome:/configrestart:unless-stoppedlabels:- traefik.http.routers.lan_esphome.rule=Host(`esphome.domain.tld`)- traefik.http.routers.lan_esphome.entrypoints=https_lan- traefik.http.routers.lan_esphome.middlewares=authelia_lan- traefik.http.routers.lan_esphome.tls=true- traefik.http.services.lan_esphome.loadbalancer.server.port=6052- traefik.enable=true ESP Home dashboard\" ESP Home dashboard You now have access to your ESP Home dashboard and can create a new configuration by clicking on the “NEW DEVICE” button. You will then have to enter some information about your device and a default configuration will be generated. esphome:name:testesp8266:board:esp01_1m# Enable logginglogger:# Enable Home Assistant APIapi:ota:password:\"ff16ebc60e9b22668b2e6fff77e6636f\"wifi:ssid:!secret wifi_ssidpassword:!secret wifi_password# Enable fallback hotspot (captive portal) in case wifi connection failsap:ssid:\"Test Fallback Hotspot\"password:\"mfp7hXdwozmk\"captive_portal: You should have something like this. The captive_portal and ap configuration will allow you to reconfigure your device in case your wifi is no longer available. The “normal” connection to your wifi is configured with the ssid and password keys. The !secret refers to the data stored in the secrets section (in the top right corner of the ui). In there you can configure your wifi credentials like this: wifi_ssid:yourssidwifi_password:yourpassword You now have the basic configuration needed to flash your device, we will now add the specific configuration to register your sensors. ","date":"2022-01-14","objectID":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/:2:0","tags":["docker","arduino","iot","home assistant","hardware"],"title":"Easily create you DIY IoT devices with ESP Home and Home Assistant","uri":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/"},{"categories":null,"content":"Create your first IoT device Here’s the device that I will make: a simple display based on 4 8×8 matrices in a wooden enclosure painted in black. The device will also have a photoresistor to adapt the brightness of the matrices and a row of 4 buttons to trigger some actions on home assistant. Everything is wired on a node mcu (with an esp8266). Wiring Finished result esphome:name:afficheurplatform:ESP8266board:nodemcuv2# Enable logginglogger:# Enable Home Assistant APIapi:ota:password:\"\"wifi:ssid:!secret \"wifi_ssid\"password:!secret \"wifi_password\"manual_ip:static_ip:10.20.8.1gateway:10.20.1.1subnet:255.255.0.0# Enable fallback hotspot (captive portal) in case wifi connection failsap:ssid:\"Afficheur Fallback Hotspot\"password:\"\"captive_portal:status_led:pin:D4#===================== display data =============================font:- file:\"pixelmix.ttf\"id:digit_fontsize:8time:- platform:homeassistantid:hass_timeglobals:- id:new_texttype:intinitial_value:\"3\"- id:txt_cyclestype:intinitial_value:\"1\"text_sensor:- platform:homeassistantname:\"afficheur texte\"entity_id:input_text.afficheur_txtid:txton_value:then:lambda:|-id(new_text) = 0;#===================== display settings =============================spi:clk_pin:D5mosi_pin:D7display:- platform:max7219digitcs_pin:D8num_chips:4rotate_chip:90id:matrixdisplayintensity:4scroll_speed:50msscroll_mode:STOPupdate_interval:3slambda:|-if (id(new_text) \u003c= id(txt_cycles)) { if(id(new_text) == 0) { id(txt_cycles) = ceil(strlen(id(txt).state.c_str()) / 6); } it.printf(0, 0, id(digit_font), \"%s\", id(txt).state.c_str()); id(new_text)++; } else { it.strftime(0, 0, id(digit_font), \" %H:%M\", id(hass_time).now()); }#===================== display control =============================number:- platform:templatename:Screen Brightnessmin_value:0max_value:15step:1set_action:then:lambda:|-id(matrixdisplay).intensity(x);switch:- platform:templatename:Screen Enableturn_on_action:then:lambda:|-id(matrixdisplay).turn_on_off(true);turn_off_action:then:lambda:|-id(matrixdisplay).turn_on_off(false);#===================== sensors =============================sensor:- platform:adcid:source_sensorpin:A0- platform:resistancesensor:source_sensorconfiguration:DOWNSTREAMresistor:10kOhmname:Resistance Sensorbinary_sensor:- platform:gpiopin:D3name:\"Btn 1\"- platform:gpiopin:D2name:\"Btn 2\"- platform:gpiopin:D1name:\"Btn 3\"- platform:gpiopin:D0name:\"Btn 4\" This is the full code for our display. I defined a status led wired on pin D4 to have a quick indication of the status of the connection (the led itself is located on the back of the display). In order to display text, you will need to configure a font, here I am using the pixelmix.ttf file that you can download here. You then need to place the font file in the same directory of your config file (in my case /app/docker/data/EspHome, see the docker-compose file). As I want to use the display as a clock when I have no message to show, I defined a time section with home assistant as the source. I also define 2 global variables to help to switch between the “message mode” and the “clock mode”, and a text sensor to allow home assistant to send a message to display. My matrices are of type max7219. They communicate using SPI, so I defined a spi section with the clk and mosi pins. I can then define a max7219digit component and specifiy the CS pin. The num_chips key indicates the number of matrices that I have connected, here 4. I used custom C++ code to define the message to display using the lambda key. This code displays the message from the text sensor if it has changed or defaults to a clock. The display is refreshed every 3 seconds. I also defined 2 template switches: a slider to control the brightness of the matrices from home assistant and a switch to turn on/off the display. For the sensors part, I defined an adc component with the pin A0 where my photoresistor is connected and a resistance component that converts the voltage to resistance and reports it to home assistant. I als","date":"2022-01-14","objectID":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/:3:0","tags":["docker","arduino","iot","home assistant","hardware"],"title":"Easily create you DIY IoT devices with ESP Home and Home Assistant","uri":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/"},{"categories":null,"content":"Flashing the ESP To flash your esp click on the install button. For the first time I recommand to use the Manual Dowload option and use ESPHome-Flasher (you can also flash it using a chrome-based browser but it will be slower). Futures updates can be done via OTA so you will only need to plug your device to your computer for the first installation. Firmware download screen Firmware compilation Flashing the firmare with ESPHome-Flasher You are now ready to go ! Your device will connect to your wifi and should appear in the device section of home assistant. The device section in the configuration A card with all the device controls The finished result I would highly recommend ESP Home as it is a really interesting framework to create specific firmware for your IoT devices. It also allows a great saving of time compared to the development of a custom firmware in C ++ “from scratch”. So I can only recommend to check out their website for more information. ","date":"2022-01-14","objectID":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/:4:0","tags":["docker","arduino","iot","home assistant","hardware"],"title":"Easily create you DIY IoT devices with ESP Home and Home Assistant","uri":"/2022/01/14/easily-create-you-diy-iot-devices-with-esp-home-and-home-assistant/"},{"categories":null,"content":"I was always interested in going furether than the pre-made RGB equipement by various manufacturers because each system was only compatible with only one brand (ex: iCUE, RGB Fusion, Asus RGB …) and that their RGB softwares were very unfinished and didn’t exploit the full potential of the RGB hardware. ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:0:0","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"First Attempt So, when I built my first desktop PC, I decided to create from scratch a custom RGB system. This was based on an arduino board, internally connected to my PC using USB. This arduino was controlling cheap adressable RGB strips (WS2812B) powered by my PSU in 5v. On the software side, I developped a custom C# application, LedControl. This was my first attempt at controlling my RGB leds. The window mounted on the pc with the arduino control box in a HDD slot (on the left) and the WS2812B leds mounted on the window (on the right)\" The window mounted on the pc with the arduino control box in a HDD slot (on the left) and the WS2812B leds mounted on the window (on the right) My custom software in C#\" My custom software in C# A bit later, while adding RGB fans, I discovered that they were using the same type of adressable leds. Unfortunately, only an input port was available, meaning that you were not able to chain the devices and control their leds individually. So, in order to control every led of my system, I needed to wire each fan data line to a dedicated port on the arduino. As there wasn’t enough ports on the nano (and that a mega was too big), I needed to add a second arduino. Going from the first to the second version (with 2 arduinos)\" Going from the first to the second version (with 2 arduinos) Example of WS2812B led strip, notice the white arrow next to the data pin, indicating the correct side to add more leds\" Example of WS2812B led strip, notice the white arrow next to the data pin, indicating the correct side to add more leds This system was working quite well, my software was able to control each device and leds individually and to apply multiple effects at the same time (ex: GPU Temp reactive lighting for a fan, CPU Temp for another fan, and music reactive effect for the window’s leds). However it wasn’t able to interact with built-in RGB like the leds on the motherboard/GPU and also had a quite limited set of effects available. Control of the window/fans’s RGB leds on the left, wiring of the next version (see below) on the right\" Control of the window/fans’s RGB leds on the left, wiring of the next version (see below) on the right ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:1:0","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Second Attempt ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:0","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"WLED So, when I renewed my computer and bought a new case, I decided to completely change the RGB lighting system. A lot of things happened after I created my first solution, and the ESP8266/ESP32 were now very common and had received a lot of support from the opensource community. Among the incredible amount of projects, was WLED, a RGB control program for these wifi chips that allowed you to control various led strips, including the WS2812B from a web interface and much more. I decided to use this project as a base to control the WS2812B-based RGB in my PC. As mutli-pin control (required for my fans) wasn’t available in the provided firmware, I neded to slightly edit the source-code and recompile it. Starting from version 0.12.0, multi-strips are supported in the precompiled binaries and are easily configurables. After wriring all my led strips, I connected my pc to the wireless hostpot created by the esp and configured the my home wifi credentials, and that’s it. I was now able to connect to the web ui of WLED and control my PC’s RGB from any device. WLED has a lot of really cool features such as synchronizing with other WLED devices, E1.31 support, an incredibly complete list of effects and the ability to define independant zones on the light strip. WLED Web UI WLED sync config page ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:1","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"OpenRGB Once that the control of the WS2812B RGB was settled, I neded to find a way to control the build-in RGB of my motherboad, RAM, GPU and keyboard. That’s where another awesome software enters: OpenRGB. This is what is tieing everything together: OpenRGB is a cross-platform software that is able to control practically any RGB device from many manufacturers like Corsair, Asus, Gigabyte, HyperX, MSI … It also supports controlling devices using E1.31 and exposes an universal API to control all of them. Most of the devices are auto-detected but for E1.31 , you need to manually edit the configuration file in %appdata%/OpenRGB/OpenRGB.json to specify the IP of the device (here, our WLED esp). Also, keep in mind that access to some devices control interfaces (like SMBus) may be blocked by other softwares, especially anti-cheats like Vanguard. OpenRGB UI OpenRGB config file ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:2","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Aurora A first options is to use Aurora-Project, to interact in real time with some games and apply some effects based on the game’s data. Aurora supports many well-known games like CS:GO, Minecraft, LoL … and a lot of different devices and protocols, including OpenRGB. So we just need to enable OpenRGB in Aurora (it will automatically connect to your local OpenRGB instance) and start the OpenRGB API Server to be able to use these effects. Aurora devices config tab Aurora game effects config (CS:GO) There are also some other software using the OpenRGB API, like KeyboardVisualizer (from the same author) that creates music-based lighting effects. Example in CS:GO, the F1-12 line represents your life and the 1-9 keys represents your ammo level\" Example in CS:GO, the F1-12 line represents your life and the 1-9 keys represents your ammo level ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:3","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Custom effects Another option is to use directly the OpenRGB API to create new effects. Fortunately a lot of wrappers in multiple languages already exists for this API. Here, we’ll be using python-openrgb. We will take Forza Horizon 5 as an example (as this is the latest game that I played). This game is has an option in Settings \u003e HUD and Gameplay to send UDP telemetry packets while playing, we will use this data to create our effects. To decode these packets we will use the ForzaDataPacket class from the forza_motorsport project. We will, in the first time, use a little script (test.py, see code below) to gather a bit of data and graph it with matplotlib, to have an idea of the evolution of these metrics. Forza Settings Forza data graph We can then map these values to RGB colors using a custom script (see below) and send them to OpenRGB. To determine which key you want to light-up, you can click on Toggle LED View in OpenRGB to show the emplacements of your keys, you can then use keyboard.matrix_map[y][x] to get the correct led id. Also note that spaces between keys also counts as keys, for example, the F1 key has the id 2 (and not 1) because of the space between the escape key (id: 0) and this key. With this script, the 1-9 keys of the keyboard represent your position in a race, the line below represents the engine rpm, below is the speed and the last line is the power. The insert/suppr/page up/page down keys represent the slip ratio for each tire and the lines 1/4/7 2/5/8 and 3/6/9 on the numpad represent your car’s status (acceleration/brake/handbrake). OpenRGB Keyboard View Forza Demo import socket from openrgb import OpenRGBClient from openrgb.utils import RGBColor, DeviceType from numpy import interp from fdp import ForzaDataPacket # get fdp.py from https://github.com/nettrom/forza_motorsport s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) server_address = (\"127.0.0.1\", 1010) s.bind(server_address) print(\"####### Server is listening #######\") client = OpenRGBClient(\"127.0.0.1\", 6742, \"forza\") keyboard = client.get_devices_by_type(DeviceType.KEYBOARD)[0].zones[0] props = [ \"speed\", \"fuel\", \"race_pos\", \"accel\", \"brake\", \"handbrake\", \"current_engine_rpm\", \"power\", \"tire_slip_ratio_FL\", \"tire_slip_ratio_FR\", \"tire_slip_ratio_RL\", \"tire_slip_ratio_RR\", \"is_race_on\", ] RED = RGBColor(255, 0, 0) YELLOW = RGBColor(255, 255, 0) ORANGE = RGBColor(255, 165, 0) GREEN = RGBColor(0, 255, 0) CYAN = RGBColor(0, 255, 255) MAGENTA = RGBColor(255, 0, 255) BLACK = RGBColor(0, 0, 0) props_keys = {} i = 0 for x in props: props_keys[x] = i i += 1 kb_black_keys = [] for i in range(len(keyboard.matrix_map)): for j in keyboard.matrix_map[i]: if j is not None: kb_black_keys.append(BLACK) def value2color(val, min, max, inverted=False): red = [0, 1, 2, 3, 4] orange = [20, 21, 22, 23, 24] yellow = [30, 31, 32, 33, 34] green = [50, 51, 52, 53, 54] if inverted: colors = red + orange + yellow + green else: colors = ( list(reversed(green)) + list(reversed(yellow)) + list(reversed(orange)) + list(reversed(red)) ) return RGBColor.fromHSV( colors[round(interp(val, [min, max], [0, len(colors) - 1]))], 100, 100 ) def keys2band(kb, start_line, start_col, nb): band = [] n = 0 for i in range(start_col, len(kb.matrix_map[start_line])): if kb.matrix_map[start_line][i] is not None: band.append(kb.matrix_map[start_line][i]) n += 1 if n \u003e nb: break return band KB_LINE1 = keys2band(keyboard, 3, 2, 10) KB_LINE2 = keys2band(keyboard, 4, 2, 10) KB_LINE3 = keys2band(keyboard, 5, 2, 10) def value2band(val, val_min, val_max, band, colors): max = len(band) - 1 nb_keys = int(interp(val, [val_min, val_max], [0, max])) i = 0 for x in band[0:nb_keys]: colors[x] = value2color(i, 0, max) i += 1 client.clear() while True: raw, address = s.recvfrom(1024) data = ForzaDataPacket(raw, \"fh4\").to_list(props) keyboard.colors = kb_black_keys.copy() if data[props_keys[\"race_pos\"]] != 0: key = 10 if data[props_keys[\"race_pos\"]] \u003e 9 else data[props_keys[\"race_pos\"]] keyboard.colors[key","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:4","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Home Assistant Home Assistant card with the different devices (on the left) and a device control popup (on the right)\" Home Assistant card with the different devices (on the left) and a device control popup (on the right) In addition to your RGB software on your PC, you can also control everything from your home automation system. For example, in Home Assistant, you can configure the WLED integration to control your PC’s led stips. Using HACS, you can also install the OpenRGB integration, which will then allow you to control all of your computer’s RGB devices using OpenRGB. ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:2:5","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Conclusion We now have a complete RGB lighting system for our computer with dynamic game-based lighting effects. As written in the last paragraphs, we can even control it from python scripts or home automation systems which opens the door to even more powerful connections (for example make your first fan blink when you receive a new message, or sync your RGB with an ambilight system …). ","date":"2021-11-29","objectID":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/:3:0","tags":["arduino","home assistant","esp8266","hardware","RGB","python"],"title":"Upgrading your RGB with WLED, Aurora and OpenRGB","uri":"/2021/11/29/upgrading-your-rgb-with-wled-aurora-and-openrgb/"},{"categories":null,"content":"Introduction A few months ago, I stumbled upon the DS Linux project while browsing the internet. The project is not actively developed anymore (which was to expect as the DS is a pretty old device with the first model released in 2004). However, working builds are available on their website here and I wanted to play a bit with it. ","date":"2020-11-03","objectID":"/2020/11/03/control-your-light-with-a-nintendo-ds/:1:0","tags":["docker","home assistant","iot","nintendo ds","python"],"title":"Control your lights with a Nintendo DS","uri":"/2020/11/03/control-your-light-with-a-nintendo-ds/"},{"categories":null,"content":"Installation According to the project’s website, DS Linux is compatible with the original DS and the DS Lite (this is the one that I own), and maybe the newer models in compatibility mode. To install it on my DS Lite, I downloaded the dslinux-dldi version, as I own a memory expansion pack (which allows to store and edit configuration), and extracted the content at the root of the sd card. In the linux/etc directory, copy the rc.defaults as rc.conf and edit the configuration, especially the following variables: enable_network_on_boot=\"YES\" essid=\"YOURSSID\" wepkey=\"s:YOURKEY\" ip=\"10.20.5.5\" netmask=\"255.255.0.0\" gateway=\"10.20.1.1\" dns1=\"10.20.1.1\" You can now start your DS and shoud be able to connect to your network (note that the DS only supports wep encryption). If you have a telnet server somewhere on your network you can try to connect to it with telnet SERVERIP. The DS connected to a DD-Wrt router over telnet\" The DS connected to a DD-Wrt router over telnet Warning The technologies used here like WEP and Telnet are very insecure, please take some security measures to use the following project. Here are some ideas: stop the container (and access point, if dedicated) when you aren’t using it, create a special access point with limited number of connection, mac filtering, client isolation and restricted network access. For example, my dedicated ap is connected to the IoT VLAN which can only access selected ports on my server and don’t has access to the Internet. ","date":"2020-11-03","objectID":"/2020/11/03/control-your-light-with-a-nintendo-ds/:2:0","tags":["docker","home assistant","iot","nintendo ds","python"],"title":"Control your lights with a Nintendo DS","uri":"/2020/11/03/control-your-light-with-a-nintendo-ds/"},{"categories":null,"content":"The Software So, DS Linux comes with a telnet and an ssh client but as the project hasn’t been updated for several years, all the ssh ciphers are deprecated, the telnet was then the easier way to connect to a server. On the server side, I made a simple docker container with a telnet server and the default shell set to a custom python script. For this script, I used python and whiptail to create a TUI to control home-assistant via its api. You can find this part on my github repo. Just edit the ip, token and devices in the python script, build and run the container. For a faster connection when booting the DS, you can edit the linux/etc/autologin.conf file, set EXEC=/home/ds.sh and create the script linux/home/ds.sh with: #!/bin/sh telnet YOURSERVERIP Now, you just need to start your DS, wait for telnet connection and enter your credentials (by default: ds/ds), you can then navigate in the menus using the DS directional cross and A/B buttons. The DS booting with linux and connecting to WiFi The DS connected to the container with the control interface ","date":"2020-11-03","objectID":"/2020/11/03/control-your-light-with-a-nintendo-ds/:3:0","tags":["docker","home assistant","iot","nintendo ds","python"],"title":"Control your lights with a Nintendo DS","uri":"/2020/11/03/control-your-light-with-a-nintendo-ds/"},{"categories":null,"content":"Introduction Wake on Lan is a technology delvelopped in 1995, that allows you to start a computer by sending a magic packet (usually in udp). I use it since a few years and it is especially useful when you are in a remote place, you can just start your computer and connect to it through rdp. The only problem is that this approach is not really suitable for dual-boot setups. ","date":"2020-10-06","objectID":"/2020/10/06/wake-on-lan-and-dual-boot/:1:0","tags":["arduino","boostrap","c++","cordova","web","wol","hardware"],"title":"Wake on Lan and Dual Boot","uri":"/2020/10/06/wake-on-lan-and-dual-boot/"},{"categories":null,"content":"The Problem Sometimes, I need to run linux process that are using the GPU, so until the gpu support is added to the WSL2, a dual-boot is mandatory for me. However, a magic packet allows you to start you computer but you have no way to interact with it until the os is fully started. So it’s impossible to access boot menu using wake on lan. ","date":"2020-10-06","objectID":"/2020/10/06/wake-on-lan-and-dual-boot/:2:0","tags":["arduino","boostrap","c++","cordova","web","wol","hardware"],"title":"Wake on Lan and Dual Boot","uri":"/2020/10/06/wake-on-lan-and-dual-boot/"},{"categories":null,"content":"The Solution So, if it’s impossible to do it in software, let’s use some hardware ! Our setup will be very simple: an Arduino Leonardo and an Ethernet Shield. Why a leonardo and not a uno or a nano ? Because, the Arduino Leonardo have a different kind of usb controller that allows to emulate an HID device, especially a keyboard in our case. Arduino Leonardo with Ethernet shield\" Arduino Leonardo with Ethernet shield The idea is to connect an ethernet shield to this arduino, so that we can send an http request with the os to start. The arduino will then send a magic packet (which is really simple to create as it is composed of 6x “FF” and 16x the mac address of the computer), wait for a predetermined amount of time (time to show the os selection screen), and then emulate the up/down/enter keys to select the correct os. #include \u003cSPI.h\u003e#include \u003cEthernet.h\u003e#include \"Keyboard.h\" #define bootDelay 9000 //time to get the boot menu from wol, in ms #define keyPressDelay 100 //in ms #define resetDelay 4 byte mac[] = { 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }; int wolPort = 9; byte remote_MAC_ADD[] = { 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }; byte broadCastIp[] = { 255, 255, 255, 255 }; IPAddress ip(192, 168, 1, 5); EthernetServer server(80); void setup() { Keyboard.begin(); Ethernet.begin(mac, ip); if (Ethernet.hardwareStatus() == EthernetNoHardware || Ethernet.linkStatus() == LinkOFF) { return; } server.begin(); } void loop() { EthernetClient client = server.available(); if (client) { // an http request ends with a blank line String message = \"\"; boolean currentLineIsBlank = true; while (client.connected()) { if (client.available()) { char c = client.read(); // if you've gotten to the end of the line (received a newline // character) and the line is blank, the http request has ended, // so you can send a reply if (c == '\\n' \u0026\u0026 currentLineIsBlank) { String param = message.substring(5, message.indexOf(\"HTTP\")-1); // send a standard http response header client.println(\"HTTP/1.1 200 OK\"); client.println(\"Access-Control-Allow-Origin: *\"); if(param == \"\") { client.println(\"Content-Type: text/html\"); client.println(\"Connection: close\"); client.println(); client.print(F(\\ \"\u003chtml\u003e\\ \u003chead\u003e\\ \u003ctitle\u003eWake On Lan\u003c/title\u003e\\ \u003cmeta name='viewport' content='width=device-width, initial-scale=1'\u003e\\ \u003cstyle\u003ehtml{background-color:#222222;}.pure-button{display:inline-block;line-height:normal;white-space:nowrap;vertical-align:middle;text-align:center;cursor:pointer;-webkit-user-drag:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-box-sizing:border-box;box-sizing:border-box}.pure-button::-moz-focus-inner{padding:0;border:0}.pure-button-group{letter-spacing:-.31em;text-rendering:optimizespeed}.opera-only :-o-prefocus,.pure-button-group{word-spacing:-.43em}.pure-button-group .pure-button{letter-spacing:normal;word-spacing:normal;vertical-align:top;text-rendering:auto}.pure-button{font-family:inherit;font-size:100%;padding:.5em 1em;color:rgba(0,0,0,.8);border:none transparent;background-color:#e6e6e6;text-decoration:none;border-radius:2px}.pure-button-hover,.pure-button:focus,.pure-button:hover{background-image:-webkit-gradient(linear,left top,left bottom,from(transparent),color-stop(40%,rgba(0,0,0,.05)),to(rgba(0,0,0,.1)));background-image:linear-gradient(transparent,rgba(0,0,0,.05) 40%,rgba(0,0,0,.1))}.pure-button:focus{outline:0}.pure-button-active,.pure-button:active{-webkit-box-shadow:0 0 0 1px rgba(0,0,0,.15) inset,0 0 6px rgba(0,0,0,.2) inset;box-shadow:0 0 0 1px rgba(0,0,0,.15) inset,0 0 6px rgba(0,0,0,.2) inset;border-color:#000}.pure-button-disabled,.pure-button-disabled:active,.pure-button-disabled:focus,.pure-button-disabled:hover,.pure-button[disabled]{border:none;background-image:none;opacity:.4;cursor:not-allowed;-webkit-box-shadow:none;box-shadow:none;pointer-events:none}.pure-button-hidden{display:none}.pure-button-primary,.pure-button-selected,a.pure-button-primary,a.pure-button-selected{background-color","date":"2020-10-06","objectID":"/2020/10/06/wake-on-lan-and-dual-boot/:3:0","tags":["arduino","boostrap","c++","cordova","web","wol","hardware"],"title":"Wake on Lan and Dual Boot","uri":"/2020/10/06/wake-on-lan-and-dual-boot/"},{"categories":null,"content":"Conclusion So with less than $50, you can create a Wake On Lan device that supports multi-os systems. You could even bring wake up support to an incompatible computer using a realy or an optocoupler to “manually push the button”. ","date":"2020-10-06","objectID":"/2020/10/06/wake-on-lan-and-dual-boot/:4:0","tags":["arduino","boostrap","c++","cordova","web","wol","hardware"],"title":"Wake on Lan and Dual Boot","uri":"/2020/10/06/wake-on-lan-and-dual-boot/"},{"categories":null,"content":"Introduction With the recent turn of events (upcoming requirement of a facebook account to use your oculus), I finally decided to get my oculus working fully offline, but it was harder than I thought. ","date":"2020-10-04","objectID":"/2020/10/04/use-your-oculus-rift-completly-offline/:1:0","tags":["batch","oculus","offline","reverse engineering","vr"],"title":"Use your oculus rift completly offline","uri":"/2020/10/04/use-your-oculus-rift-completly-offline/"},{"categories":null,"content":"First Attempt Indeed, if you can use your headset without an internet connection, you still need to have the oculus software installed. So, after some research, I came across this topic where a user describes how to backup the installer files to use it offline. So I tested it and …. Screenshot of non-working installer\" Screenshot of non-working installer Yeah, the current installer (tested with version 1.51.0.0) checks for an internet connection before starting the install process. So, I started Fiddler to see which requests are sent by this little software. However, with the HTTPS decoding enabled, the installer won’t work and we can’t see anything useful in fiddler. This behavior is probably due to the use of SSL-Pinning (we can also confirm that by checking the installer logs), which is a method more and more used to prevent this kind of attack. So, unless we can alter the hash stored inside the installer, this is a dead-end. ","date":"2020-10-04","objectID":"/2020/10/04/use-your-oculus-rift-completly-offline/:2:0","tags":["batch","oculus","offline","reverse engineering","vr"],"title":"Use your oculus rift completly offline","uri":"/2020/10/04/use-your-oculus-rift-completly-offline/"},{"categories":null,"content":"Second Attempt So, I switched to another method, and decided to just re-create the installer because … why not ? An installer is just copying files and adjusting some settings, so I should be able to do that too. But in order to archieve that, I needed to know exectly what this installer is doing. First I searched for oculus stuff in some key locations in the registry and backuped them, I also used a driver store explorer to see which drivers are installed to the headset and backuped them with this command: dism /online /export-driver /destination:\"BACKUP_FOLDER\". I also knew that there was 2 services installed for the oculus software: “OVRService” which handles most of the work and “OVRLibraryService” which manages your oculus games, so I wrote down the path of the executables used in these services. To backup and restore all of these components, I decided to use batch scripts, as they are natively supported on windows and are easily ediatables. To restore drivers I used the following command: pnputil /add-driver \"BACKUP_FOLDER\\*.inf\" /subdirs /install and to re-create the service, I used this one: sc.exe create OVRService binpath=\"PATH_TO_OCULUS“. But after an unsuccessful try, I looked in the oculus logs in AppData\\Local\\Oculus and I saw that registy keys were missing, so I re-runned the official installer while using a software named ProcessMonitor that allwed me to record all system modifications (especially filesystem and registry operations). Screenshot of Process Monitor\" Screenshot of Process Monitor Thanks to ProcessMonitor, I found the remaining registry keys, but also an easier way to install drivers and services. Indeed, I noticed that the installer called this executable in Support\\oculus-drivers\\oculus-driver.exe which handles driver installation. Same for OVRService which is installed with the command: Support\\oculus-runtime\\OVRServiceLauncher.exe\" -install -start. I also needed to backup some of the AppData folders, like Appdata\\Local\\Oculus which stores the headset settings, and AppData\\Roaming\\Oculus which stores the account setttings (so you absolutely need to backup and restore this in order to skip the online login procedure when launching the oculus-client for the first time). Finally, I needed to block any communication with Facebook servers (for obvious privacy concerns) which was possible by simply pointing the domains found in the first attempt to localhost, using the hosts file (located in %windir%\\System32\\drivers\\etc\\hosts). ","date":"2020-10-04","objectID":"/2020/10/04/use-your-oculus-rift-completly-offline/:3:0","tags":["batch","oculus","offline","reverse engineering","vr"],"title":"Use your oculus rift completly offline","uri":"/2020/10/04/use-your-oculus-rift-completly-offline/"},{"categories":null,"content":"Conclusion With all of these data, I was able to successfuly create backup, install and uninstall scripts for the Oculus software that will run without internet access, making it possible to preserve the use of my vr headset forever. Of course, these scripts are freely available to everyone on my github here. ","date":"2020-10-04","objectID":"/2020/10/04/use-your-oculus-rift-completly-offline/:4:0","tags":["batch","oculus","offline","reverse engineering","vr"],"title":"Use your oculus rift completly offline","uri":"/2020/10/04/use-your-oculus-rift-completly-offline/"},{"categories":null,"content":"Introduction Hello, I am Thomas, a student currently in the third year of a bachelor’s degree in computer science. I am interested in many aspects of technology including (but not limited to) front-end and back-end programming, reverse-engeineering, 3D printing, VR, networking, system administration, home automation, etc … and I am sharing my different projects on this blog. Here is a quick overview.  Github    Linkedin    RSS    Mail ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Skills Programming Python PHP Golang C++ C# Java SQL (MariaDB / Oracle/ Postgres) HTML5 / CSS Javascript (web and nodeJS) VueJS Quasar, Bootstrap REST API, Web Sockets CS Skills Networking Docker Linux administration CI/CD Git Office Tools (PIX Certification n° 68412) Other Languages: French (native, Voltaire Certification n° 6YHRM7) 🇫🇷 English (B2 level) 🇺🇸 Other: Economy and comptability basics Project management Agile and SCRUM methods Law basics ","date":"0001-01-01","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Work Experience 2021: Elcimaï 3 months internship to create a continuous integration system and adapt the existing projects (.NET Core, .NET Framework, Ionic/JS/angular) ","date":"0001-01-01","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Eduction 2021 – 2022: Sorbonne Université I am currenty studying at Sorbonne Université (Paris, France) and I am in the third year of a bachelor’s degree in computer science. 2019 – 2021: URCA I studied at URCA (Reims University, France) for two years in order to complete my two-years degree in computer science. 2019: JASA I got my high school diploma in 2019, with high honours mention in scientific series. ","date":"0001-01-01","objectID":"/about/:4:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Hobbies Apart from programming (which is still my principal hobby), I like to play video games, watch tv shows and animes and read novels and mangas (in french or english). In sports, I like biking and swiming, which are very relaxing sports, and pleasant to do after a week of work. I also used to do model railroading a few years ago. ","date":"0001-01-01","objectID":"/about/:5:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Last updated: August 24, 2020 DrosoBlog (“us”, “we”, or “our”) operates the DrosoBlog website (the “Service”). This page informs you of our policies regarding the collection, use and disclosure of Personal Information when you use our Service. We will not use or share your information with anyone except as described in this Privacy Policy. We use your Personal Information for providing and improving the Service. By using the Service, you agree to the collection and use of information in accordance with this policy. Unless otherwise defined in this Privacy Policy, terms used in this Privacy Policy have the same meanings as in our Terms and Conditions, accessible at https://thomasz.me ","date":"0001-01-01","objectID":"/privacy-policy/:0:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Information Collection And Use While using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you. Personally identifiable information (“Personal Information”) may include, but is not limited to: Email address ","date":"0001-01-01","objectID":"/privacy-policy/:1:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Log Data We collect information that your browser sends whenever you visit our Service (“Log Data”). This Log Data may include information such as your computer’s Internet Protocol (“IP”) address, browser type, browser version, the pages of our Service that you visit, the time and date of your visit, the time spent on those pages and other statistics. ","date":"0001-01-01","objectID":"/privacy-policy/:2:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Cookies Cookies are files with small amount of data, which may include an anonymous unique identifier. Cookies are sent to your browser from a web site and stored on your computer’s hard drive. We use “cookies” to collect information. You can instruct your browser to refuse all cookies or to indicate when a cookie is being sent. However, if you do not accept cookies, you may not be able to use some portions of our Service. ","date":"0001-01-01","objectID":"/privacy-policy/:3:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Service Providers We may employ third party companies and individuals to facilitate our Service, to provide the Service on our behalf, to perform Service-related services or to assist us in analyzing how our Service is used. These third parties have access to your Personal Information only to perform these tasks on our behalf and are obligated not to disclose or use it for any other purpose. Security The security of your Personal Information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage is 100% secure. While we strive to use commercially acceptable means to protect your Personal Information, we cannot guarantee its absolute security. ","date":"0001-01-01","objectID":"/privacy-policy/:4:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Links To Other Sites Our Service may contain links to other sites that are not operated by us. If you click on a third party link, you will be directed to that third party’s site. We strongly advise you to review the Privacy Policy of every site you visit. We have no control over, and assume no responsibility for the content, privacy policies or practices of any third party sites or services. ","date":"0001-01-01","objectID":"/privacy-policy/:5:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Children’s Privacy Our Service does not address anyone under the age of 18 (“Children”). We do not knowingly collect personally identifiable information from children under 18. If you are a parent or guardian and you are aware that your child has provided us with Personal Information, please contact us. If we discover that a child under 18 has provided us with Personal Information, we will delete such information from our servers immediately. ","date":"0001-01-01","objectID":"/privacy-policy/:6:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Compliance With Laws We will disclose your Personal Information where required to do so by law or subpoena. Changes To This Privacy Policy We may update our Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this Privacy Policy periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page. ","date":"0001-01-01","objectID":"/privacy-policy/:7:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Contact Us If you have any questions about this Privacy Policy, please contact us. ","date":"0001-01-01","objectID":"/privacy-policy/:8:0","tags":null,"title":"Privacy Policy","uri":"/privacy-policy/"},{"categories":null,"content":"Personnal Projects \u003c \"\u003e Zogwine Media Center This project is a media center with a golang backend and a VueJS / Quasar frontend (PWA). This is my main project. \u003c \"\u003e Simple Docker UI Simple web ui in python and bootstrap to view container logs and status and start/stop them. Configuration is done with a simple json file. Amazfit Viewer A single php page to upload results from my phone to a database and visualize the data of my smart watch. DLauncher A simple game launcher with time tracking and save syncing between devices. Written in nodeJS (electron) and bootstrap. LedControl A C# application to control and apply different effects to my computer RGB devices (ram, fans and ledstrips) with an arduino. Offculus A collection of batch scripts to allow offline installation of the oculus software. Heimdallite A lighter version of heimdall, this is a single php page configured with a json file, instead of a whole php framework and database. Downloader2 Automated scraping of webpages with Puppeteer to retreive download links. Dockerized with a xvfb display and a noVNC server to handle captchas. BSCM Beat Saber Co-op Mod, written in C# to allow 2 player to play together, each one holding one saber. \u003c \"\u003e Home Assistant Integrations A lot of custom components for home assistant, written in python, from reverse-engineered api and softwares. \u003c \"\u003e Streamdeck Plugins OSD Sidekick plugin (based on gigabyte’s software reverse engineering) and Drone CI plugin (to check build status and deploy to specific targets) \u003c \"\u003e IP Blocker Software to block IPs on OPNsense firewall based on a gelf stream from Graylog. Written in python. \u003c \"\u003e Marks Notifier Discord bot to autmoatically send notifications when a new mark is added. Written in nodeJS with puppeteer to retreive data from an internal network using Jupyter and a python notebook. \u003c \"\u003e docker-bstreamer Docker image used to stream a browser’s video/audio over RTSP. Also includes a noVNC server and a proxy for puppeteer. \u003c \"\u003e DBackup A database backup solution. Supports MySQL/MariaDB, Postgres, Influx DB (v1) and MongoDB. Compresses the backups into a single zip on a regular basis (cron). Written in python and running in docker. \u003c \"\u003e NetBackup A network configuration backup solution. Supports SwitchOS, DLink Switches, OPNsens and OpenWRT. Saves the backups on a git repo on a regular basis (cron). Written in python and running in docker. \u003c \"\u003e Synology Exporter A logs and metrics exporter for old synology NAS (DSM 3.1). Exports logs to Graylog using GELF and metrics to InfluxDB, using some endpoint of the DSM web ui. \u003c \"\u003e NoUpdateLauncher A simple program to prevent some steam games to update when launching them. Based on a webmanifest hack and using python, VDF and PySimpleGUI. \u003c \"\u003e ATV Remote Android TV / Google TV remote protocol implementation in golang. \u003c \"\u003e IDFM-API Python wrapper for Ile de france mobilités API. ","date":"0001-01-01","objectID":"/projects/:1:0","tags":null,"title":"Projects","uri":"/projects/"},{"categories":null,"content":"School Projects \u003c \"\u003e Static Website Static website built with bootstrap for our first semester project. Made with Clement D. \u003c \"\u003e Solitaire A CLI solitaire game written in php, in one week for our first project of second semester. Made with Clement D. \u003c \"\u003e Multiplayer Prophunt A multiplayer game built with A-Frame and nodeJS, in one week with a group of 2 people (second semester project). Made with Clement D. \u003c \"\u003e Delivery App A delivery app like Uber Eats with order and delivery management using custom algorithms. Built with React-Native, PHP and MariaDB. This is our current project for the third semester. \u003c \"\u003e Balkanimes Extensible automated downloader, written in nodeJS, VueJS and GraphQL, for our 4th semester project. Made with Clement D. \u003c \"\u003e Network Analyzer A multiplatform network trace analyzer supporting Ethernet, IPv4, UDP, DHCP and DNS. Written in node js and typescript and available as a web app or desktop app using electron. ","date":"0001-01-01","objectID":"/projects/:2:0","tags":null,"title":"Projects","uri":"/projects/"},{"categories":null,"content":"Notables Contributions Add onlyoffice integration to filebrowser Add option to use remote instance of chromium (for puppeteer) to wappalyzer Add support for notifications using apprise to epicgames-freebies-claimer Fix steam library detection in Aurora Project Add remote auth header to FreshRSS ","date":"0001-01-01","objectID":"/projects/:3:0","tags":null,"title":"Projects","uri":"/projects/"},{"categories":null,"content":"Last updated: August 24, 2020 Please read these Terms of Use (“Terms”, “Terms of Use”) carefully before using the https://thomasz.me website (the “Service”) operated by DrosoBlog (“us”, “we”, or “our”). Your access to and use of the Service is conditioned on your acceptance of and compliance with these Terms. These Terms apply to all visitors, users and others who access or use the Service. By accessing or using the Service you agree to be bound by these Terms. If you disagree with any part of the terms then you may not access the Service. Intellectual Property The Service and its original content, features and functionality are and will remain the exclusive property of DrosoBlog and its licensors. ","date":"0001-01-01","objectID":"/terms-of-use/:0:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Links To Other Web Sites Our Service may contain links to third-party web sites or services that are not owned or controlled by DrosoBlog. DrosoBlog has no control over, and assumes no responsibility for, the content, privacy policies, or practices of any third party web sites or services. You further acknowledge and agree that DrosoBlog shall not be responsible or liable, directly or indirectly, for any damage or loss caused or alleged to be caused by or in connection with use of or reliance on any such content, goods or services available on or through any such web sites or services. We strongly advise you to read the terms and conditions and privacy policies of any third-party web sites or services that you visit. ","date":"0001-01-01","objectID":"/terms-of-use/:1:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Termination We may terminate or suspend access to our Service immediately, without prior notice or liability, for any reason whatsoever, including without limitation if you breach the Terms. All provisions of the Terms which by their nature should survive termination shall survive termination, including, without limitation, ownership provisions, warranty disclaimers, indemnity and limitations of liability. ","date":"0001-01-01","objectID":"/terms-of-use/:2:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Disclaimer Your use of the Service is at your sole risk. The Service is provided on an “AS IS” and “AS AVAILABLE” basis. The Service is provided without warranties of any kind, whether express or implied, including, but not limited to, implied warranties of merchantability, fitness for a particular purpose, non-infringement or course of performance. ","date":"0001-01-01","objectID":"/terms-of-use/:3:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Governing Law These Terms shall be governed and construed in accordance with the laws of France without regard to its conflict of law provisions. Our failure to enforce any right or provision of these Terms will not be considered a waiver of those rights. If any provision of these Terms is held to be invalid or unenforceable by a court, the remaining provisions of these Terms will remain in effect. These Terms constitute the entire agreement between us regarding our Service, and supersede and replace any prior agreements we might have between us regarding the Service. ","date":"0001-01-01","objectID":"/terms-of-use/:4:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Changes We reserve the right, at our sole discretion, to modify or replace these Terms at any time. If a revision is material we will try to provide at least 15 days notice prior to any new terms taking effect. What constitutes a material change will be determined at our sole discretion. By continuing to access or use our Service after those revisions become effective, you agree to be bound by the revised terms. If you do not agree to the new terms, please stop using the Service. ","date":"0001-01-01","objectID":"/terms-of-use/:5:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"},{"categories":null,"content":"Contact Us If you have any questions about these Terms, please contact us. ","date":"0001-01-01","objectID":"/terms-of-use/:6:0","tags":null,"title":"Terms and Conditions","uri":"/terms-of-use/"}]